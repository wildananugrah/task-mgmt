# PostgreSQL Configuration for Task Management App
# Optimized for high-concurrency workload (1000+ concurrent users)
# Server specs assumed: 8GB RAM, 2-4 vCPUs

# ===========================================
# CONNECTION SETTINGS
# ===========================================
max_connections = 300
# Must be higher than DATABASE_POOL_MAX (200) + buffer for admin connections
# Each connection uses ~10MB RAM, so 300 * 10MB = ~3GB

# ===========================================
# MEMORY SETTINGS
# ===========================================
# For 8GB RAM server with PostgreSQL in Docker:
# Total RAM: 8GB
# OS + App: ~4-5GB
# PostgreSQL: ~3GB available

shared_buffers = 512MB
# Recommended: 25% of RAM for dedicated DB server
# For shared server (DB + App): 512MB-768MB is safe

effective_cache_size = 2GB
# Estimate of memory available for disk caching
# Should be ~50-75% of total RAM
# This doesn't allocate memory, just tells planner what's available

work_mem = 16MB
# Memory for each sort/hash operation
# With 300 connections, 16MB * 300 = 4.8GB max
# Keep this reasonable to avoid OOM

maintenance_work_mem = 128MB
# Memory for VACUUM, CREATE INDEX, ALTER TABLE
# Can be higher since these operations are less frequent

# ===========================================
# WRITE AHEAD LOG (WAL) SETTINGS
# ===========================================
wal_buffers = 16MB
# Amount of memory used in shared memory for WAL data
# -1 = auto (1/32 of shared_buffers, up to 16MB)

checkpoint_completion_target = 0.9
# Spread out checkpoint I/O over 90% of checkpoint interval
# Reduces I/O spikes

# ===========================================
# QUERY PLANNER
# ===========================================
random_page_cost = 1.1
# Lower for SSD storage (default is 4.0 for HDD)
# SSDs have fast random access, so sequential vs random cost is similar

effective_io_concurrency = 200
# Number of concurrent disk I/O operations
# For SSD: 200-300
# For HDD: 2-4

# ===========================================
# AUTOVACUUM
# ===========================================
autovacuum = on
autovacuum_max_workers = 3
autovacuum_naptime = 1min

# ===========================================
# LOGGING (for monitoring performance)
# ===========================================
log_min_duration_statement = 1000
# Log queries taking longer than 1 second
# Helps identify slow queries

log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
# Include timestamp, process ID, user, database in logs

log_connections = on
log_disconnections = on
log_lock_waits = on
# Log connection events and lock waits for debugging

# ===========================================
# STATISTICS
# ===========================================
shared_preload_libraries = 'pg_stat_statements'
# Track execution statistics of all SQL statements
# Requires: CREATE EXTENSION pg_stat_statements;

track_activity_query_size = 2048
# Increase query text length in pg_stat_activity

# ===========================================
# NOTES
# ===========================================
# After changing this file:
# 1. Restart PostgreSQL: docker-compose restart task-mgmt-db
# 2. Verify settings: docker exec -it task-mgmt-db psql -U postgres -c "SHOW max_connections;"
# 3. Check all settings: docker exec -it task-mgmt-db psql -U postgres -f /scripts/check-pg-settings.sql
